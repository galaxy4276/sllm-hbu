# 온디바이스 Big5 심리 분석 리포트 앱 PRD

### 1. 개요

#### 1.1 프로젝트 개요
- **프로젝트명**: 하루온 (Haru-On) - 온디바이스 Big5 심리 분석 리포트 앱
- **프로젝트 목표**: 사용자의 Big5 성격 특성을 분석하는 심리학적 리포트를 사용자 기기 내부에서(On-Device) 직접 생성하여 제공

#### 1.2 핵심 가치 제안
- **데이터 프라이버시 극대화**: 사용자의 민감한 답변(심리 상태)을 외부 서버로 전송하지 않음
- **오프라인 기능 제공**: 인터넷 연결 없이도 앱의 핵심 기능(분석 리포트 생성) 사용 가능
- **즉각적인 경험**: 서버 지연 시간 없이 빠른 분석 결과 제공

### 2. 제품 범위

#### 2.1 포함 범위 (In-Scope)
- Big5 모델 기반 5개 질문 제공 및 답변 입력 UI
- 사용자 답변(텍스트)을 입력받아 분석 리포트(텍스트)를 생성하는 온디바이스 sLLM 탑재
- 생성된 심리 분석 리포트 표시 UI
- 모델 로딩 및 리포트 생성 중 상태 표시(로딩 인디케이터 등)

#### 2.2 제외 범위 (Out-of-Scope)
- 사용자 계정 시스템 (회원가입, 로그인)
- 서버 기반 데이터 백업 및 동기화
- 리포트 외부 공유 기능 (단, 텍스트 복사 기능은 포함)
- Big5 외 다른 심리 검사 모델

### 3. 사용자 요구사항

#### 3.1 기능적 요구사항

**FR-01: 질문 응답**
- FR-01.1: 사용자는 Big5 성격 특성(개방성, 성실성, 외향성, 우호성, 신경성)에 기반한 5개의 고정된 질문을 순차적으로 제공받음
- FR-01.2: 각 질문마다 사용자가 답변을 작성하는 데 참고할 수 있는 '힌트' 텍스트 제공
- FR-01.3: 각 질문의 답변은 자유 텍스트 형식이며, 최대 500자까지 입력 가능
- FR-01.4: 사용자는 현재 진행 상태(예: "3/5")를 시각적으로 인지할 수 있어야 함

**FR-02: 모델 구동**
- FR-02.1: 앱은 리포트 생성 요청 전에 온디바이스 sLLM을 메모리에 로드해야 함
- FR-02.2: 모델 로딩(초기화) 중에는 사용자에게 명확한 로딩 상태(예: "분석 엔진을 준비 중입니다...")를 표시해야 함
- FR-02.3: 모델 로드 실패 시, 사용자에게 오류 메시지와 함께 재시도 옵션을 제공해야 함

**FR-03: 리포트 생성**
- FR-03.1: 사용자가 5개의 답변을 모두 완료하고 '분석하기' 버튼을 누르면, 5개의 답변 텍스트가 조합되어 sLLM을 위한 단일 프롬프트로 변환되어야 함
- FR-03.2: 생성된 프롬프트는 즉시 온디바이스 sLLM에 전달되어 추론을 시작해야 함
- FR-03.3: 모델이 리포트를 생성하는 동안(추론 시간), 사용자에게 "리포트를 작성 중입니다..."와 같은 진행 상태를 표시해야 함
- FR-03.4: sLLM은 입력된 5개 답변을 기반으로 Big5 특성별 분석 내용과 종합 의견이 포함된 텍스트 리포트를 생성해야 함

**FR-04: 리포트 표시**
- FR-04.1: 생성된 텍스트 리포트는 사용자에게 가독성 높은 UI(적절한 폰트 크기, 줄 바꿈, 섹션 구분)로 제공되어야 함
- FR-04.2: 리포트 내용은 특성별(예: #개방성, #성실성...)로 명확히 구분되어야 함
- FR-04.3: 사용자는 생성된 리포트 텍스트 전체를 클립보드에 복사할 수 있어야 함

#### 3.2 비기능적 요구사항

**NFR-01: 성능**
- NFR-01.1: Apple iPhone 15 Pro (A17 Pro 칩)를 1차 성능 벤치마크 기준
- NFR-01.2: 모델의 메모리 로드 시간은 5초 이내 목표
- NFR-01.3: 5개의 답변(총 2,500자 이내) 입력 기준, 리포트 생성 완료까지의 총 추론 시간은 15초 이내 목표

**NFR-02: 프라이버시 및 보안**
- NFR-02.1: 사용자의 모든 답변 및 생성된 리포트 데이터는 사용자 기기 외부(서버 등)로 일절 전송되지 않아야 함
- NFR-02.2: 모든 데이터 처리는 기기 내부에서 완결되어야 함(100% On-Device)

**NFR-03: 리소스**
- NFR-03.1: 양자화된 sLLM (GGUF) 모델 파일을 포함한 앱의 총 설치 용량(iOS)은 1.5GB를 초과하지 않도록 권장
- NFR-03.2: 모델 로드 및 추론 시, 과도한 RAM 점유로 인해 OS에 의해 앱이 강제 종료되지 않아야 함

**NFR-04: 호환성 및 개발 환경**
- NFR-04.1: 앱은 Expo (React Native) 프레임워크를 기반으로 개발
- NFR-04.2: 네이티브 모듈(sLLM) 연동을 위해 Expo Go가 아닌 Expo Development Client 또는 Prebuild 방식 사용
- NFR-04.3: 1차 출시 타겟은 iOS (최신 버전 - 2)

**NFR-05: 사용성**
- NFR-05.1: 앱의 모든 핵심 기능(질문 응답, 리포트 생성)은 인터넷 연결이 없는 오프라인 상태에서 완벽하게 동작해야 함

### 4. 기술 아키텍처

#### 4.1 시스템 아키텍처
```
flowchart TD
    subgraph 📱 Expo App (React Native)
        A[UI: 질문 화면] -- 5개 답변 제출 --> B{JS: 프롬프트 생성기};
        B -- 생성된 프롬프트 --> C[Native Module Bridge (e.g., llama.rn)];
        C -- 결과(Report) 반환 --> D{JS: 상태 관리};
        D -- 리포트 텍스트 --> E[UI: 리포트 화면];
    end

    subgraph ⚙️ Native Layer (iOS)
        C <--> F[On-Device sLLM (llama.cpp)];
        F -- 구동 --> G[(GGUF 모델 파일)];
    end

    style F fill:#f9f,stroke:#333,stroke-width:2px
    style G fill:#lightgrey,stroke:#333,stroke-width:2px
```

#### 4.2 AI 모델 사양
- **기본 모델**: Qwen2-1.5B (또는 Qwen2-0.5B)
- **선정 사유**:
  - 성능: 1.5B 파라미터 수준에서 강력한 한국어 이해력과 문장 생성 능력 보유
  - 크기: 4비트 양자화 시 약 1GB 내외로 모바일 앱 번들에 포함하기에 현실적인 용량
  - 라이선스: 상업적 이용이 가능한 라이선스(Apache 2.0)

#### 4.3 모델 페르소나
튜닝된 모델이 생성하는 리포트는 다음과 같은 페르소나를 일관되게 유지해야 함:

| 특성 | 설명 |
|------|------|
| 전문성 (Professional) | 심리학적 용어(Big5)를 정확하게 사용하되, 쉽고 명확하게 설명 |
| 공감 능력 (Empathetic) | 사용자의 답변을 비판하거나 판단하지 않음. 긍정적인 면을 부각하고 수용적인 태도 |
| 통찰력 (Insightful) | 단순히 답변을 요약하는 것이 아니라, 답변에 내포된 성향을 추론하고 연결 |
| 조심성 (Cautious) | 절대 단정적인 진단(Diagnosis)을 내리지 않음. "...한 성향을 보이네요", "...일 가능성이 높습니다"와 같이 가능성을 제시하는 어조 사용 |
| 구조화 (Structured) | 리포트는 항상 [특성별 분석]과 [종합 의견]이라는 명확한 구조를 따름 |

### 5. 사용자 시나리오

#### 5.1 주요 사용자 시나리오

**시나리오 1: 처음 사용하는 사용자**
1. 앱 실행 → 온보딩 화면 표시
2. Big5 질문 시작 버튼 클릭
3. 5개의 질문에 대해 각각 답변 입력 (힌트 참조)
4. 모든 답변 완료 후 '분석하기' 버튼 클릭
5. 모델 로딩 → 분석 진행 → 리포트 생성
6. 생성된 리포트 확인 및 복사

**시나리오 2: 오프라인 환경에서의 사용**
1. 인터넷 연결 없이 앱 실행
2. 모든 기능이 오프라인에서 정상 작동하는지 확인
3. 질문 응답 → 리포트 생성까지 모든 단계 완료

### 6. 제약 사항

#### 6.1 기술적 제약
- C-01: 리포트 생성 AI 모델은 Qwen 계열의 sLLM을 파인 튜닝하여 사용
- C-02: 온디바이스 추론 엔진은 `llama.cpp` 및 GGUF 형식을 우선적으로 고려
- C-03: 리포트의 품질은 100% 파인 튜닝된 sLLM의 성능에 의존하며, 정해진 규칙 기반(Rule-based) 로직을 사용하지 않음

#### 6.2 성능 제약
- NFR-01.2: 모델 로딩 시간 5초 이내
- NFR-01.3: 리포트 생성 시간 15초 이내
- NFR-03.1: 앱 총 설치 용량 1.5GB 이내

### 7. 성공 기준

#### 7.1 핵심 성공 기준 (KSC)
1. **품질 (Quality)**: 생성된 리포트가 모델 페르소나를 90% 이상 일관되게 준수하는가?
2. **정확성 (Accuracy)**: 5개의 입력 답변과 리포트의 분석 내용 간의 논리적 연관성이 명확한가?
3. **안전성 (Safety)**: 모델이 '진단'이나 '처방'과 같은 의료적/단정적 표현을 생성하지 않는가?
4. **성능 (Performance)**: 양자화된 모델(Q4_K_M)이 iPhone 15 Pro에서 15초 이내에 리포트 생성을 완료하는가?

### 8. 용어 정의

- **Big5**: 5대 성격 특성 모델. 개방성(Openness), 성실성(Conscientiousness), 외향성(Extraversion), 우호성(Agreeableness), 신경성(Neuroticism)
- **sLLM (Small Language Model)**: 모바일 기기 등 제한된 리소스 환경에서 실행 가능하도록 파라미터 수를 줄인 경량화 언어 모델
- **On-Device AI**: 외부 서버와의 통신 없이, 사용자 기기 내부의 연산 장치(NPU, GPU 등)를 사용하여 AI 모델을 실행하는 기술
- **GGUF**: `llama.cpp` 라이브러리에서 사용하는 표준 모델 파일 형식. 양자화 및 모델 메타데이터를 포함
- **Expo Dev Client**: Expo Go와 달리 커스텀 네이티브 코드를 포함할 수 있게 해주는 Expo 개발용 클라이언트 빌드