## 1. 튜닝 기획 (The Plan)

### 1.1. 프로젝트 목표

본 튜닝 프로젝트의 목표는 **'범용 sLLM'**을 **'심리 분석 전문가'**로 특수화(Specialization)하는 데 있다.

- **최종 산출물:** 5개의 Big5 질문에 대한 사용자 답변(Input)을 받아, 전문적이고 통찰력 있는 심리학적 분석 리포트(Output)를 생성하는 파인 튜닝된(Fine-tuned) sLLM.

- **핵심 요건:** 생성된 리포트는 반드시 **온디바이스(On-Device)** 환경에서 구동되어야 하며, 제3자의 개입(서버) 없이 독립적으로 추론을 완료해야 한다.


### 1.2. 타겟 모델 선정

- **기본 모델 (Base Model):** **Qwen2-1.5B** (또는 Qwen2-0.5B)

- **선정 사유:**

    - **성능:** 1.5B 파라미터 수준에서 강력한 한국어 이해력과 문장 생성 능력을 보유하고 있다.

    - **크기:** 4비트 양자화(Quantization) 시 약 1GB 내외로, 모바일 앱 번들에 포함하기에 현실적인 용량이다.

    - **라이선스:** 상업적 이용이 가능한 라이선스(Apache 2.0)를 따른다.


### 1.3. 모델 페르소나 (Persona) 정의

튜닝된 모델이 생성하는 리포트는 다음과 같은 페르소나를 일관되게 유지해야 한다. 이는 훈련 데이터셋(2.1절) 구축의 핵심 가이드라인이 된다.

|**특성**|**설명**|
|---|---|
|**전문성 (Professional)**|심리학적 용어(Big5)를 정확하게 사용하되, 쉽고 명확하게 설명한다.|
|**공감 능력 (Empathetic)**|사용자의 답변을 비판하거나 판단하지 않는다. 긍정적인 면을 부각하고 수용적인 태도를 보인다.|
|**통찰력 (Insightful)**|단순히 답변을 요약하는 것이 아니라, 답변에 내포된 성향을 추론하고 연결한다.|
|**조심성 (Cautious)**|**절대 단정적인 진단(Diagnosis)을 내리지 않는다.** "...한 성향을 보이네요", "...일 가능성이 높습니다"와 같이 가능성을 제시하는 어조를 사용한다.|
|**구조화 (Structured)**|리포트는 항상 [특성별 분석]과 [종합 의견]이라는 명확한 구조를 따라야 한다.|

### 1.4. 입출력 명세 (I/O Specification)

모든 훈련 데이터는 일관된 프롬프트 템플릿을 따라야 한다.

코드 스니펫

```
graph TD
    subgraph 훈련 데이터 (JSONL)
        direction TB
        A[System Prompt<br/>"당신은 Big5 심리 분석 전문가입니다..."] --> C
        B[User Input<br/>"개방성: ...<br/>성실성: ..."] --> C
        C{튜닝 데이터 쌍}
        C --> D[Model Output<br/>"## 심리 분석 리포트<br/>* 개방성: ..."]
    end

    subgraph 런타임 (Expo App)
        direction TB
        E[User Answers] --> F[프롬프트 템플릿 적용]
        F --> G[Tuned sLLM (GGUF)]
        G --> H[생성된 리포트]
    end
```

### 1.5. 핵심 성공 기준 (KSC)

1. **품질 (Quality):** 생성된 리포트가 1.3절의 '모델 페르소나'를 90% 이상 일관되게 준수하는가?

2. **정확성 (Accuracy):** 5개의 입력 답변과 리포트의 분석 내용 간의 논리적 연관성이 명확한가?

3. **안전성 (Safety):** 모델이 '진단'이나 '처방'과 같은 의료적/단정적 표현을 생성하지 않는가?

4. **성능 (Performance):** 양자화된 모델(Q4_K_M)이 iPhone 15 Pro에서 15초 이내에 리포트 생성을 완료하는가?


---

## 2. 튜닝 절차 안내서 (The Procedure)

### 2.1. 1단계: 훈련 데이터셋 구축 (Data Curation) - 가장 중요

품질이 낮은 데이터 10,000개보다 품질이 높은 데이터 100개가 더 낫다.

- **포맷:** **JSONL (JSON Lines)**

- **구조:** 지시(Instruction) 튜닝을 위한 표준 ChatML 또는 Alpaca 형식

    - _권장: Qwen2 모델은 ChatML 형식을 공식 지원하므로 ChatML을 권장한다._


**ChatML 형식 예시:**

JSON

```
{"messages": [{"role": "system", "content": "당신은 Big5 심리학 모델을 기반으로 사용자의 답변을 분석하는 전문 심리 분석가입니다. 사용자의 5가지 답변을 바탕으로, 각 특성(개방성, 성실성, 외향성, 우호성, 신경성)을 분석하고 긍정적이며 통찰력 있는 종합 리포트를 작성해주세요. 절대 의학적 진단을 내리지 마세요."}, {"role": "user", "content": "1. 개방성: '요즘은 주말마다 새로운 베이킹 레시피를 배우는 게 가장 즐거워요. 새로운 걸 배우는 것 자체가 에너지를 줍니다.'\n2. 성실성: '계획했던 일을 마치면 정말 뿌듯하고, 스스로에 대한 자신감이 생겨요. 체크리스트를 지워나가는 쾌감이 있습니다.'\n3. 외향성: '솔직히 혼자 있을 때가 더 편해요. 사람들과 있는 것도 좋지만, 결국 에너지는 혼자 책 읽거나 쉬면서 충전돼요.'\n4. 우호성: '친구가 힘들어하면 일단 무슨 일인지 끝까지 들어주려고 노력해요. 공감해주고 옆에 있어 주는 편입니다.'\n5. 신경성: '스트레스를 받으면 잠을 잘 못 자고 예민해져요. 주로 혼자 조용한 음악을 듣거나 산책하면서 풀려고 합니다.'"}, {"role": "assistant", "content": "## Big5 심리 분석 리포트\n\n당신의 답변을 바탕으로 분석한 성격 특성은 다음과 같습니다.\n\n* **개방성 (Openness): 높음**\n    '새로운 레시피 배우기'에서 즐거움을 얻는다는 점에서, 당신은 새로운 경험과 지식에 대해 매우 개방적인 성향을 보입니다. 호기심이 많고 배움을 즐기는 모습이 뚜렷합니다.\n\n* **성실성 (Conscientiousness): 매우 높음**\n    '계획'과 '체크리스트'를 통해 '뿌듯함'과 '자신감'을 얻는 모습은 매우 높은 성실성을 나타냅니다. 책임감이 강하고 목표 지향적이며 체계적인 성격입니다.\n\n* **외향성 (Extraversion): 낮음 (내향성)**\n    에너지를 '혼자 있을 때' 얻는다고 명확히 답한 부분에서 내향적인 성향이 강하게 드러납니다. 사회적 교류보다는 개인적인 시간을 통해 재충전하는 타입입니다.\n\n* **우호성 (Agreeableness): 높음**\n    타인의 말을 '끝까지 들어주고 공감'하려는 태도는 높은 우호성을 시사합니다. 타인에게 협조적이며 공감 능력이 뛰어난 따뜻한 성격입니다.\n\n* **신경성 (Neuroticism): 다소 높음**\n    스트레스 상황에서 '잠을 못 자고 예민해지는' 반응은 정서적 민감성(신경성)이 다소 높을 수 있음을 보여줍니다. 다만, '음악 듣기', '산책' 등 건강한 방식으로 해소하려 노력하는 점도 긍정적입니다.\n\n**종합 의견:**\n당신은 성실하고 책임감이 강하며, 새로운 지식에 열려있는 '학습자' 유형입니다. (이하 생략)"}]}
```

- **데이터 확보 전략:**

    1. **수동 생성 (100건):** 1.3절의 페르소나를 완벽하게 따르는 **황금 데이터(Golden Data)**를 직접 작성한다.

    2. **합성 데이터 생성 (400~900건):** GPT-4, Claude 3 등 고성능 LLM을 활용하여 가상의 'user' 답변과 'assistant' 리포트 쌍을 대량 생성한다.

    3. **검수 및 정제:** 합성된 데이터가 페르소나를 벗어나거나(예: '당신은 우울증입니다'), 논리가 맞지 않는 경우를 **반드시 수동으로 검수하고 수정**한다.

- **목표 수량:** 초기 튜닝 500~1,000건


### 2.2. 2단계: 파인 튜닝 실행 (Fine-Tuning)

- **도구:** `LLaMA-Factory`, `Axolotl` 또는 Hugging Face `TRL` (SFTTrainer)

    - _권장: `LLaMA-Factory`_ - 다양한 모델과 튜닝 기법(LoRA, QLoRA)을 웹 UI 또는 CLI로 쉽게 설정할 수 있다.

- **튜닝 기법:** **QLoRA (Quantized Low-Rank Adaptation)**

    - **이유:** 4비트로 양자화된 상태에서 모델을 튜닝하여, 단일 GPU(예: RTX 4090 또는 VRAM 24GB 이상)에서도 1.5B 모델을 효율적으로 튜닝할 수 있다.

- **주요 하이퍼파라미터 설정 (예시):**

    - `model_name_or_path`: `Qwen/Qwen2-1.5B`

    - `dataset`: `path/to/your_dataset.jsonl`

    - `finetuning_type`: `lora`

    - `q_lora`: `True` (QLoRA 활성화)

    - `lora_rank`: 64

    - `lora_alpha`: 128

    - `learning_rate`: `1e-4` (sLLM은 약간 높게 시작 가능)

    - `num_train_epochs`: 3

    - `max_seq_length`: 2048 (입력+출력 토큰 길이 고려)


### 2.3. 3단계: 모델 병합 및 테스트 (Merge & Test)

1. **LoRA 어댑터 병합:** 튜닝이 완료되면 QLoRA 어댑터(가중치)가 생성된다. 이 어댑터를 원본 Qwen2-1.5B 모델에 병합하여 단일 튜닝 모델(Hugging Face 형식)을 생성한다.

2. **기능 테스트:** 병합된 모델을 로드하여, 훈련에 사용되지 않은 **별도의 테스트용 질문지**를 입력해본다.

3. **결과 평가:**

    - 페르소나(1.3절)를 잘 따르는가?

    - 엉뚱한 답변(Hallucination)은 없는가?

    - 안전성(1.5절)을 위반하지 않는가?

    - _결과가 만족스럽지 않으면, 2.1단계로 돌아가 데이터셋을 보강한다. (예: 모델이 실수한 부분과 유사한 정답 데이터를 추가)_


### 2.4. 4단계: GGUF 변환 및 양자화 (Conversion)

이 단계는 `llama.cpp`를 사용하여 모바일 배포용 모델을 만드는 과정이다.

1. **GGUF 변환:** 3단계에서 병합된 모델(Hugging Face 폴더)을 `llama.cpp`의 `convert.py` 스크립트를 사용하여 GGUF (FP16) 형식으로 변환한다.

   Bash

    ```
    # llama.cpp 저장소 내부에서 실행
    python convert.py /path/to/merged_hf_model \
      --outfile qwen2-1.5b-tuned.gguf \
      --outtype f16 
    ```

2. **4비트 양자화:** 변환된 GGUF(FP16) 모델을 `quantize` 프로그램을 사용하여 4비트(Q4_K_M)로 양자화한다.

   Bash

    ```
    # llama.cpp/build/bin/quantize 경로 (컴파일 후)
    ./quantize qwen2-1.5b-tuned.gguf \
      qwen2-1.5b-tuned.Q4_K_M.gguf \
      Q4_K_M
    ```

3. **최종 산출물:** `qwen2-1.5b-tuned.Q4_K_M.gguf` 파일 (약 1.0GB~1.2GB)


### 2.5. 5단계: 앱 배포 및 최종 검증

1. **모델 탑재:** 4단계에서 생성된 `...Q4_K_M.gguf` 파일을 Expo (React Native) 프로젝트의 `assets` 폴더에 포함시킨다.

2. **네이티브 연동:** `llama.rn` 또는 Expo 네이티브 모듈을 사용하여 이 모델 파일을 로드하고 추론을 수행한다.

3. **최종 검증 (NFR):** iPhone 15 Pro 실기기에서 모델 로딩 속도(NFR-01.2)와 리포트 생성 속도(NFR-01.3)를 측정한다.